# 1. Decision Tree Modeling Process
Decision tree modeling is an important supervised learning algorithm. Like previous clustering algorithms, decision tree model is a general caterogy for a type of model.
Decision tree models are very high efficiency, high prediction accuracy, process is simple and clear, and it is a "white-box" model.
**Decision tree models can do both regression and classification prediction**, it also can output feature significance. In essemble learning, the most commonly used basic classifier is tree model.

## 1.1 Build decision tree iwth logistic regression
The essentials of building a decision tree is to dig effective classification rules.

## 1.2 Decision tree categories
Decision tree model is not an algorithm, it is a category of algorithms. Followings are most popular ones:
- ID3 (Iterative Dichotomiser 3)、C4.5、 C5.0 decision tree
- CART decisioin tree (classification and regression trees), or C&RT. sklearn decision tree is mostly based on CART model.
- CHAID decition tree (Chi-square automatic interaction detection).

# 2. CART classification trees using sklearn
## 2.1 CART classification process
How do we build the estimator is the key factor. Accuracy is no more suitable for decision trees. We use purity as the key estimator. Here are three key purity estimators for CART:
- Classification error
- Entropy
- Gini
> [!IMPORTANT]
> - ID3、C4.5、C5.0 use entropy
> - Cart use Gini
> - Greedy algorithm use classification error
Another question is to estimator multiple data sets' purity.
## 2.2 Implement CART classification tree with Scikit-Learn
```python
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor

DecisionTreeClassifier?
```
| Name  | Description |
| ------------- | ------------- |
| criterion  | estimator or loss function, default is gini coefficient, user can select information entropy {"gini", "entropy"} |
| splitter  | tres model grow method, default is grow with loss function reduce most fastly {"best", "random"}  |
| max_depth  | The maximum depth of the tree. like max_iter  |
| splitter  | tres model grow method, default is grow with loss function reduce most fastly  |
| min_samples_split  | minimal data sample to split  |
| min_samples_leaf  | minimal data sample of leaf nodes  |
| min_weight_fraction_leaf  | minimal weight sum of leaf nodes  |
| max_features  | number of features to consider when looking for the best split, default=None  |
| random_state  | random seed  |
| max_leaf_nodes  | maximum leaf nodes number  |
| min_impurity_decrease  | minimum gini/entropy loss to further grow tree  |
| class_weight  |  different sample weights |
| ccp_alpha  | like regularizer, the larger alpha is, the larger structural risk is  |

# 3. CART regression trees using sklearn
CART regression model can solve regression problems. Also, it is an important basic unit for assemble algorithm - GBDT.
> [!IMPORTANT]
> For assemble algorithm, no matter regression or classification problems, CART regression tree is the only basic unit.






















