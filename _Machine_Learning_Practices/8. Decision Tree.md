# 1. Decision Tree Modeling Process
Decision tree modeling is an important supervised learning algorithm. Like previous clustering algorithms, decision tree model is a general caterogy for a type of model.
Decision tree models are very high efficiency, high prediction accuracy, process is simple and clear, and it is a "white-box" model.
**Decision tree models can do both regression and classification prediction**, it also can output feature significance. In essemble learning, the most commonly used basic classifier is tree model.

Decision tree is the basic component of random forest and an intuitive model. We can think of a decision tree as a series of yes/no questions about the data that ultimately lead to an answer to a classification or regression problem. The technical details of decision trees lie in how questions about the data are formed. In the CART algorithm, a decision tree is constructed by determining questions (called node splits) that will cause the Gini coefficient (Gini Impurity) to decay as quickly as possible after being answered. This means that the decision tree is trying to form nodes that classify the data as quickly as possible by finding appropriate thresholds (dichotomous comparison values) among the features that cleanly separate the data into different classes.


## 1.1 Build decision tree with logistic regression
The essentials of building a decision tree is to dig effective classification rules.

## 1.2 Decision tree categories
Decision tree model is not an algorithm, it is a category of algorithms. Followings are most popular ones:
- ID3 (Iterative Dichotomiser 3)、C4.5、 C5.0 decision tree
- CART decisioin tree (classification and regression trees), or C&RT. sklearn decision tree is mostly based on CART model.
- CHAID decition tree (Chi-square automatic interaction detection).

# 2. CART classification trees using sklearn
## 2.1 CART classification process
How do we build the estimator is the key factor. Accuracy is no more suitable for decision trees. We use purity as the key estimator. Here are three key purity estimators for CART:
- Classification error
- Entropy
- Gini
> [!IMPORTANT]
> - ID3、C4.5、C5.0 use entropy
> - Cart use Gini
> - Greedy algorithm use classification error

Another question is to estimator multiple data sets' purity.
## 2.2 Implement CART classification tree with Scikit-Learn
```python
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor

DecisionTreeClassifier?
```
| Name  | Description |
| ------------- | ------------- |
| criterion  | estimator or loss function, default is gini coefficient, user can select information entropy {"gini", "entropy"} |
| splitter  | tres model grow method, default is grow with loss function reduce most fastly {"best", "random"}  |
| max_depth  | The maximum depth of the tree. like max_iter  |
| splitter  | tres model grow method, default is grow with loss function reduce most fastly  |
| min_samples_split  | minimal data sample to split  |
| min_samples_leaf  | minimal data sample of leaf nodes  |
| min_weight_fraction_leaf  | minimal weight sum of leaf nodes  |
| max_features  | number of features to consider when looking for the best split, default=None  |
| random_state  | random seed, this seed will determine the "randomness" of the above splitter and max_features. If the random seed is determined, then splitter and max_features are determined. If random_state is not specified, then there is a lot of randomness, and the model will be inconsistent every time.  |
| max_leaf_nodes  | maximum leaf nodes number  |
| min_impurity_decrease  | minimum gini/entropy loss to further grow tree  |
| class_weight  |  different sample weights |
| ccp_alpha  | like regularizer, the larger alpha is, the larger structural risk is  |

> [!TIP]
> max_features is maximum number of randomly selected features for a tree

# 3. CART regression trees using sklearn
CART regression model can solve regression problems. Also, it is an important basic unit for assemble algorithm - GBDT.
> [!IMPORTANT]
> For assemble algorithm, no matter regression or classification problems, CART regression tree is the only basic unit.






















