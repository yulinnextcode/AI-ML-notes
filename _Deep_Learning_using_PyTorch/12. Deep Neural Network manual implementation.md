We have implement linear regression, logistic regression and softmax regression with neural network in previous lessons.

If the model doesn't have activation function, then the model equals to linear regression;
If the model applies sigmoid activation function at the output layer for binary classification, then the model equals to Logistic regression;
For multiple classification, applies softmax activation function at the output layer, then the model equals to Softmax regression;



<details>
<summary><h1>1. Functions to create dateset for deep learning modeling experiments</h1></summary>

```python
import random

import matplotlib as mpl
import matplotlib.pyplot as plt

import numpy as np

import torch
from torch import nn, optim
import torch.nn.functional as F
from torch.utils.data import Dataset, TensorDataset, DataLoader
```

## 1.1 Manually create datasets for regression

```python
num_inputs = 2
num_examples = 1000

torch.manual_seed(420)

w_true = torch.tensor([2,-1]).reshape(2,1)
b_true = torch.tensor(1.0)

features = torch.randn(num_examples, num_inputs)
labels_true = torch.mm(features, w_true) + b_true
labels = labels_true + torch.randn(size=labels_true.shape)*0.01

plt.subplot(121)
plt.scatter(features[:,0], labels)
plt.subplot(122)
plt.scatter(features[:,1], labels)

torch.manual_seed(420)
labels1 = labels_true + torch.randn(size = labels_true.shape) * 2

# small disturb
plt.subplot(221)
plt.scatter(features[:,0], labels)
plt.subplot(222)
plt.plot(features[:,1], labels, 'ro')

# large disturb
plt.subplot(221)
plt.scatter(features[:,0], labels1)
plt.subplot(222)
plt.plot(features[:,1], labels1, 'yo')

```
> [!TIP]
> plot vs scatter
> For ploting large points, scatter is faster than plot
> For distingushing points, plot is better than scatter

```python
torch.manual_seed(420)

w_true = torch.tensor([2,-1]).reshape(2,1)
b_true = torch.tensor(1.0)

features = torch.randn(num_examples, num_inputs)
labels_true = torch.pow(features, 2) * w_true + b_true    #y=x^2+1
labels = labels_true + torch.randn(size=labels_true.shape)*0.01

plt.scatter(features, labels)
```

## 1.2 Functions to create datasets for regression

```python
def tensorGenReg(num_examples=1000, w=[2,-1,1], bias=True, delta=0.01, deg=1)
  if bias==True:
    num_inputs=len(w)-1
    features_true=torch.randn(num_examples, num_inputs)
    w_true=torch.tensor(w[:-1]).reshape(-1,1).float()
    b_true=torch.tensor(w[-1]).float()
    if num_inputs == 1:
      labels_true = torch.pow(features_true, deg) * w_true + b_true
    else:
      labels_true = torch.mm(torch.pow(features_true, deg), w_true) + b_true
    features = torch.cat((features_true, torch.ones(len(features_true), 1)), 1)
    labels = labels_true + torch.randn(size = labels_true.shape) * delta
  else:
    num_inputs = len(w)
    features = torch.randn(num_examples, num_inputs)
    w_true = torch.tensor(w).reshape(-1,1).float()
    if num_inputs == 1:
      labels_true = torch.pow(features_true, deg) * w_true + b_true
    else:
      labels_true = torch.mm(torch.pow(features_true, deg), w_true) + b_true
    labels = labels_true + torch.randn(size = labels_true.shape) * delta
  return features, labels
```
> [!TIP]
> Above function can not create cross product items
```python
torch.manual_seed(420)

f, l = tensorGenReg(delta=1)

plt.subplot(221)
plt.scatter(f[:,0], 1)
plt.subplot(222)
plt.scatter(f[:,1], 1)
```
```python
torch.manual_seed(420)

f, l = tensorGenReg(delta=2)

plt.subplot(221)
plt.scatter(f[:,0], 1)
plt.subplot(222)
plt.scatter(f[:,1], 1)
```
2nd order relationship
```python
torch.manual_seed(420)

f, l = tensorGenReg(deg=2)

plt.subplot(221)
plt.scatter(f[:,0], 1)
plt.subplot(222)
plt.scatter(f[:,1], 1)
```
## 1.3 Manually create datasets for classification
> [!TIP]
> 
> torch.randn(4,2) returns standard normalization distribution
> 
> torch.normal(4,2,size=(10,2)) returns normalization distribution, which average is 4 and standard variance is 2
```python

torch.manual_seed(420)

data0=torch.normal(4,2,size=(num_examples, num_inputs))
data1=torch.normal(-2,2,size=(num_examples, num_inputs))
data2=torch.normal(-6,2,size=(num_examples, num_inputs))

label0=torch.zeros(500)
label1=torch.ones(500)
label2=torch.full_like(label1,2)

features=torch.cat((data0, data1, data2)).float()
labels=torch.cat((label0, label1, label2)).long().reshape(-1,1)

plt.scatter(features[:,0], features[:,1], c=labels)

```


## 1.4 Functions to create datasets for classification
```python
def tensorGenCla(num_examples=500, num_inputs=2, num_class=3, deg_dispersion=[4,2], bias=False):
  cluster_1 = torch.empty(num_examples, 1)
  mean_ = deg_dispersion[0]
  std_ = deg_dispersion[1]
  lf = []
  l1 = []
  k = mean_ + (num_class+1) / 2

  for i in range(num_class):
    data_temp = torch.normal(i*mean_-k, std_, size=(num_examples, num_inputs))
    lf.append(data_temp)
    labels_temp = torch.full_like(cluster_l, i)
    l1.append(labels_temp)

  features = torch.cat(lf).float()
  labels = torch.cat(l1).long()

  if bias == True:
    features = torch.cat((features, torch.ones(len(features), 1)), 1)

  return features, labels

f, l = tensorGenCla(deg_dispersion = [6,2])
f1, l1 = tensorGenCla(deg_dispersion = [6,4])

plt.subplot(121)
plt.scatter(f[:,0], f[:,1], c=1)
plt.subplot(122)
plt.scatter(f1[:,0], f1[:,1], c=l1)

```

## 1.5 Split batch dataset functions

```python

l=list(range(5))
random.shuffle(l)

def data_iter(batch_size, features, labels):
  num_examples = len(features)
  indices = list(range(num_examples))
  random.shuffle(indices)
  l=[]
  for i in range(0, num_examples, batch_size):
    j=torch.tensor(indices[i:min(i+batch_size, num_examples)])
    l.append([torch.index_select(features, 0, j), torch.index_select(labels, 0, j)])
  return l

torch.manual_seed(420)
features, labels = tensorGenCla()
```

## 1.6 Python modules

</details>



<details>
<summary><h1>2. Visulization tool TensorBoard installation and use for PyTorch deep learning</h1></summary>

## 1.1 TensorBoard installation

pip install tensorboardX

## 1.2 SummaryWriter class

```python

writer = SummaryWriter(log_dir='test')

writer.log_dir

for i in range(10):
  writer.add_scalar('mul', i*i, i)
```

</details>


<details>
<summary><h1>3. Linear regression modeling using deep learning</h1></summary>
  
## 1.1 Deep learning modeling implementation in 4 steps

## 1.2 PyTorch's derivable tensor in-place operation

## 1.3 Linear regression manual implementation with deep learning model

## 1.4 Linear regression auto implementation with deep learning model

</details>


<details>
<summary><h1>4. Logistic regression modeling using deep learning</h1></summary>

## 1.1 Logistic regression manual implementation with deep learning model

## 1.2 Logistic regression auto implementation with deep learning model

## 1.3 Model fine-tuning

</details>


<details>
<summary><h1>5. Softmax regression modeling using deep learning</h1></summary>

## 1.1 Softmax regression and max regression

## 1.2 Softmax regression manual implementation

## 1.3 Model stability test

## 1.4 Softmax regression auto implementation

## 1.5 Run PyTorch deep learning models with GPU

</details>



