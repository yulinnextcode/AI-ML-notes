# 1. Persistence - data volume
Docker is open-source, virtualization software created to make developer's life easy. It is a kind of PaaS (platform-as-a-service) product whose core objective is to isolate virtual environments to deploy, build, and test applications that are usually incompatible or not meant to work with the current OS.

Docker provides two ways for persistence:
- Data Volume, storage data at Docker area (specified by Docker)
- Bind Mount, storage data at the location specified by user
  
![Persistence](https://dockertips.readthedocs.io/en/latest/_images/types-of-mounts.png)

As we see from the following figure. Here are some kay points about docker image vs docker container:
- Docker images are nothing but a read-only template that can’t be executed by themselves and cannot run or start.
- Docker containers are nothing but a box that has the ability to run the docker image templates. The moment you create a container using those immutable images you essentially end up creating a read-write copy of that filesystem (docker image) inside the given container. This adds a container layer which helps you to modify the entire copy of the given Docker image.
- A Docker container is a self-contained, runnable software application or service. On the other hand, a Docker image is the template loaded onto the container to run it, like a set of instructions.
- An image is an inert, immutable, file that's essentially a snapshot of a container. Images are created with the build command, and they'll produce a container when started with run. Images are stored in a Docker registry such as registry.hub.docker.com. Because they can become quite large, images are designed to be composed of layers of other images, allowing a minimal amount of data to be sent when transferring images over the network.
- To use a programming metaphor, if an image is a class, then a container is an instance of a class—a runtime object. Containers are hopefully why you're using Docker; they're lightweight and portable encapsulations of an environment in which to run applications.
- Although Docker images and containers have a similar purpose (to package and deploy software efficiently), they have different uses. An image is a snapshot of an environment, while a container runs the software.

![image](https://github.com/yulinnextcode/skills-github-pages/assets/45866102/e890856b-807c-4f03-ac93-bc7d281285c4)

Docker image is a kind of ready-to-use software read-only template crafted with source codes, libraries, external dependencies, tools, and other miscellaneous files that are needed for any software application to run successfully on any platform or OS. The developer community also likes to call it Snapshots, representing the app and its virtual environment at a specific point in time.

Docker containers are nothing but a box that has the ability to run the docker image templates. The moment you create a container using those immutable images you essentially end up creating a read-write copy of that filesystem (docker image) inside the given container. This adds a container layer which helps you to modify the entire copy of the given Docker image.

Key difference between docker image vs docker container:
- The key difference between a Docker image Vs a container is that a Docker image is a read-only immutable template that defines how a container will be realized. A Docker container is a runtime instance of a Docker image that gets created when the $ docker run command is implemented.
- Before the docker container can even exist docker templates/images are built using $ docker build CLI.
- Docker image templates can exist in isolation but containers can't exist without images.
- So docker image is an integral part of containers that differs only because of their objectives which we have already covered.
- Docker images can’t be paused or started but a Docker container is a run time instance that can be started or paused.

Let's take the following dockerfile as an example
```dockerfile
# Dockerfile
FROM apline:3.13

RUN apk update
RUN apk --no-cache add curl
ENV SUPERCRONIC_URL=https://github.com/aptible/supercronic/releases/download/v0.1.12/supercronic-linux-amd64 \
    SUPERCRONIC=supercronic-linux-amd64 \
    SUPERCRONIC_SHA1SUM=048b95b48b708983effb2e5c935a1ef8483d9e3e
RUN curl -fsSLO "$SUPERCRONIC_URL" \
    && echo "${SUPERCRONIC_SHA1SUM} ${SUPERCRONIC}" | sha1sum -c - \
    && chmod +x "$SUPERCRONIC" \
    && mv "$SUPERCRONIC" "/usr/local/bin/&{SUPERCRONIC}" \
    && ln -s "/usr/local/bin/${SUPERCRONIC}" /usr/local/bin/supercronic

COPY my-cron /app/my-cron
WORKDIR /app

VOLUME ["/app"]   # make app folder persistence

CMD ["/usr/local/bin/supercronic", "/app/my-cron"]
```

```powershell
docker image build -t my-cron .

docker container run -d my-cron

docker container ls

docker container exec -it container_id sh

docker container stop container_id

docker volume ls

docker volume inspect volume_name

# Even if we delete the container, the data is still available in volume
# If we create a new container, then it will create a new volume. How can we use previous existing volume?
# When we create a new container, we can specify the volume name, as follows
docker container run -d -v volume_name:/app my-cron   # store folder app in volume volume_name
docker container exec -it container_name sh   # we can continue use the previous existing data and files
```

# 2. Data Volume practice MySQL

We will use MySQL official image, tag version 5.7.
Dockerfile can be found [here](https://github.com/docker-library/mysql/tree/master/5.7).

**prepare image**
```powershell
$ docker pull mysql:5.7
$ docker image ls
```
**create container**
How to use MySQL image can refer to [dockerhub](https://hub.docker.com/_/mysql?tab=description&page=1&ordering=last_updated).

How to use Dockerfile Volume can refer [here](https://github.com/docker-library/mysql/tree/master/5.7)

```powershell
$ docker container run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d -v mysql-data:/var/lib/mysql mysql:5.7
02206eb369be08f660bf86b9d5be480e24bb6684c8a938627ebfbcfc0fd9e48e
$ docker volume ls
DRIVER    VOLUME NAME
local     mysql-data
$ docker volume inspect mysql-data
[
    {
        "CreatedAt": "2021-06-21T23:55:23+02:00",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/mysql-data/_data",
        "Name": "mysql-data",
        "Options": null,
        "Scope": "local"
    }
]
$

docker container ls
docker volume ls
docker container exec -it container_id sh
```

```powershell
$ docker container exec -it 022 sh
# mysql -u root -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.7.34 MySQL Community Server (GPL)

Copyright (c) 2000, 2021, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
4 rows in set (0.00 sec)

mysql> create database demo;
Query OK, 1 row affected (0.00 sec)

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| demo               |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.00 sec)

mysql> exit
Bye
# exit
```
we created a database called demo, check data volume
```powershell
$ docker volume inspect mysql-data
[
    {
        "CreatedAt": "2021-06-22T00:01:34+02:00",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/mysql-data/_data",
        "Name": "mysql-data",
        "Options": null,
        "Scope": "local"
    }
]
$ ls  /var/lib/docker/volumes/mysql-data/_data
auto.cnf    client-cert.pem  ib_buffer_pool  ibdata1  performance_schema  server-cert.pem
ca-key.pem  client-key.pem   ib_logfile0     ibtmp1   private_key.pem     server-key.pem
ca.pem      demo             ib_logfile1     mysql    public_key.pem      sys
$
```
> [!TIP]
> If there is VOLUME definition in dockerfile, but not specify by command -v parameter, then docker will create a volume with a random name
> When creating a container, we can use the -v parameter to manually specify the name of the volume to be created and the path corresponding to the container. This path can be arbitrary and does not need to be defined by VOLUME in the Dockerfile.

# 3. Persistence - bind mount

Data volume create a mountpoint in Linux virtual machine address. Therefore when we use data volume method, we can not check the address if we use Windows (Linux machine can check that)
If we use bind mount method, we can tell docker the mount address in local for both windows and linux machine.

```powershell
docker system prune -f

docker volume prune -f

docker container run -d -v ${pwd}:/app my-cron       #   pwd means map container's /app to current directory.
```

For example, we have a Hello.c file

```c
void main(int argc, char *argv[])
{
  printf("hello %s \n", argv[argc - 1]);
}
```
> [!TIP]
> If we use windows and do not have any development environment, we can still use docker to build environment fast and efficiently
> we can also mount our current path to a specified container's path with following
> docker container run -it -v ${pwd}:/root gcc:9.4     # /root is gcc's container's root folder; gcc:9.4 is image name and tag number

# 4. Multiple machines container shared data
Previously we talked about two methods: data volume and bind mount. These two methods both storage data to local file system.
If we want to storage data to remote, we need to use docker drive. Take a look at docker volume driver.
```docker
$ docker volume inspect vscode
[
    {
        "CreatedAt": "2021-06-23T21:33:57Z",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/vscode/_data",
        "Name": "vscode",
        "Options": null,
        "Scope": "local"
    }
]
```

The default driver is local. 
Assume we have different host, and we run different containers. Different containers use shared file storage as follows. In this condition, we use ssh to connect remote storage system, and use remote machine's storage system. In order to do this, we need to use a driver called sshfs.
![docker_shared_file](https://docs.docker.com/storage/images/volumes-shared-storage.webp). 

Take a example, we can prepare three Linux machines, and they can communicate with each other by SSH
| hostname  | ip | ssh username | ssh password |
| ------------- | ------------- | ------------- | ------------- |
| docker-host1  | 192.168.200.10  | vagrant  | vagrant  |
| docker-host2  | 192.168.200.11  | vagrant  | vagrant  |
| docker-host3  | 192.168.200.12  | vagrant  | vagrant  |

we need to install a plugin on the other two machines
```powershell
[vagrant@docker-host1 ~]$ docker plugin install --grant-all-permissions vieux/sshfs
latest: Pulling from vieux/sshfs
Digest: sha256:1d3c3e42c12138da5ef7873b97f7f32cf99fb6edde75fa4f0bcf9ed277855811
52d435ada6a4: Complete
Installed plugin vieux/sshfs
```

```powershell
[vagrant@docker-host2 ~]$ docker plugin install --grant-all-permissions vieux/sshfs
latest: Pulling from vieux/sshfs
Digest: sha256:1d3c3e42c12138da5ef7873b97f7f32cf99fb6edde75fa4f0bcf9ed277855811
52d435ada6a4: Complete
Installed plugin vieux/sshfs
```

create volume
```
[vagrant@docker-host1 ~]$ docker volume create --driver vieux/sshfs \
                          -o sshcmd=vagrant@192.168.200.12:/home/vagrant \
                          -o password=vagrant \
                          sshvolume
```
```
[vagrant@docker-host1 ~]$ docker volume ls
DRIVER               VOLUME NAME
vieux/sshfs:latest   sshvolume
[vagrant@docker-host1 ~]$ docker volume inspect sshvolume
[
    {
        "CreatedAt": "0001-01-01T00:00:00Z",
        "Driver": "vieux/sshfs:latest",
        "Labels": {},
        "Mountpoint": "/mnt/volumes/f59e848643f73d73a21b881486d55b33",
        "Name": "sshvolume",
        "Options": {
            "password": "vagrant",
            "sshcmd": "vagrant@192.168.200.12:/home/vagrant"
        },
        "Scope": "local"
    }
]
```

Next, we can create container, map sshvolume to /app path, and create a test.txt file
```
[vagrant@docker-host1 ~]$ docker run -it -v sshvolume:/app busybox sh
Unable to find image 'busybox:latest' locally
latest: Pulling from library/busybox
b71f96345d44: Pull complete
Digest: sha256:930490f97e5b921535c153e0e7110d251134cc4b72bbb8133c6a5065cc68580d
Status: Downloaded newer image for busybox:latest
/ #
/ # ls
app   bin   dev   etc   home  proc  root  sys   tmp   usr   var
/ # cd /app
/app # ls
/app # echo "this is ssh volume"> test.txt
/app # ls
test.txt
/app # more test.txt
this is ssh volume
/app #
/app #
```

Then we can see this in host3 machine
```
[vagrant@docker-host3 ~]$ pwd
/home/vagrant
[vagrant@docker-host3 ~]$ ls
test.txt
[vagrant@docker-host3 ~]$ more test.txt
this is ssh volume
```

If you want to use AWS as shared storage file system, you can search corresponding driver, such as search docker volume s3 plugin




