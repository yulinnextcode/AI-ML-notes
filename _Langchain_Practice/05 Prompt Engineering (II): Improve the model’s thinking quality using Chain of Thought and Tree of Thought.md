## What is Chain of Thought

The concept of CoT (Chain of Thought) originates from academia. It was introduced by Jason Wei and others from Google Brain in their 2022 paper titled 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.

It suggests that generating a series of intermediate reasoning steps can significantly enhance the ability of large language models to perform complex reasoning.

### Few-Shot CoT

Few-Shot CoT simply provides some chain-of-thought examples in the prompt. This can enhance the reasoning ability of sufficiently large language models. In simple terms, it means giving one or two examples and clearly writing out the reasoning process in those examples.

![](images/701505/f27cec109dff8947d85507b34ce240a0.png)

In experiments with three large language models, CoT improved performance across a range of arithmetic, common sense, and symbolic reasoning tasks. In the GSM8K math problem benchmark, CoT guidance enabled the large model to achieve state-of-the-art accuracy at the time.

CoT is conceptually very easy to understand and practically very easy to implement. Although simple, this idea can provide a lot of inspiration for our development process.

For example, suppose we are developing an AI flower shop assistant whose task is to help users choose the flowers they want and generate a sales list. In this process, we can use CoT to guide the AIâ€™s reasoning process.

ğŸ‘‰ Overall guidance: You need to follow the steps below to reason step by step.

1. Problem understanding: First, the AI needs to understand the userâ€™s needs. For example, the user might say, â€˜I am going to a friendâ€™s birthday party today and want to send a bouquet to wish her well.â€™ We can give the AI a prompt template that includes an example: â€˜When faced with XX problem, I first check if I have any relevant knowledge. If I do, I provide the answer; if not, I use tools to search for information and then try to solve it.â€™ â€” This provides the AI with an example of a chain of thought.

2. Information search: Next, the AI needs to search for relevant information. For example, it might need to find out which flowers are most suitable for a birthday party.

3. Decision making: Based on the collected information, the AI needs to make a decision. We can use the chain of thought to guide it through the decision-making process, step by step. For example, we can give it an example: â€˜When faced with the situation of sending flowers for a birthday party, I first consider the userâ€™s needs, then check the flower inventory, and finally decide to recommend some roses and lilies because these flowers are usually suitable for birthday parties.â€™ â€” With this birthday party scenario as an example, the large model can apply similar thinking processes to other scenarios.

4. Generate sales list: Finally, the AI uses the OutputParser to generate a sales list, including the recommended flowers and prices.

In this process, overall, the chain of thought guides the AI from understanding the problem, to searching for information, to making decisions, and finally generating the sales list. This method not only makes the AIâ€™s reasoning process clearer but also ensures that the generated sales list better meets the userâ€™s needs. For each step, more detailed prompt templates can be designed using the chain of thought to guide the modelâ€™s thinking with clear and accurate logic.

In fact, the essence of LangChainâ€™s core component, Agent, is to perform good prompt engineering and extensively use pre-set Few-Shot and CoT templates. We will understand this more thoroughly in the subsequent lessons.

> [!IMPORTANT]
> The core component of LangChain, Agent, essentially performs good prompt engineering and extensively uses pre-set Few-Shot and CoT templates.

### Zero-Shot CoT

Few-Shot CoT refers to incorporating reasoning steps into the prompt with examples, guiding the model to produce better results. Zero-Shot CoT, on the other hand, involves directly instructing the model to think step-by-step and reason slowly.

## Chain of Thought Practice

Project Requirements: In this example, you are developing an AI operations assistant. We need to demonstrate how the AI reasons and generates answers based on user needs. Then, the AI reasons based on the current user request, providing specific flower suggestions and explaining why these suggestions were chosen.

In this process, the AI needs to understand the customerâ€™s needs, think step-by-step, and then provide the most logical response.

### CoT template design

### Program full framework

```plain
# è®¾ç½®ç¯å¢ƒå˜é‡å’ŒAPIå¯†é’¥
import os
os.environ["OPENAI_API_KEY"] = 'ä½ çš„OpenAI API Key'

# åˆ›å»ºèŠå¤©æ¨¡å‹
from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(temperature=0)

# è®¾å®š AI çš„è§’è‰²å’Œç›®æ ‡
role_template = "ä½ æ˜¯ä¸€ä¸ªä¸ºèŠ±åº—ç”µå•†å…¬å¸å·¥ä½œçš„AIåŠ©æ‰‹, ä½ çš„ç›®æ ‡æ˜¯å¸®åŠ©å®¢æˆ·æ ¹æ®ä»–ä»¬çš„å–œå¥½åšå‡ºæ˜æ™ºçš„å†³å®š"

# CoT çš„å…³é”®éƒ¨åˆ†ï¼ŒAI è§£é‡Šæ¨ç†è¿‡ç¨‹ï¼Œå¹¶åŠ å…¥ä¸€äº›å…ˆå‰çš„å¯¹è¯ç¤ºä¾‹ï¼ˆFew-Shot Learningï¼‰
cot_template = """
ä½œä¸ºä¸€ä¸ªä¸ºèŠ±åº—ç”µå•†å…¬å¸å·¥ä½œçš„AIåŠ©æ‰‹ï¼Œæˆ‘çš„ç›®æ ‡æ˜¯å¸®åŠ©å®¢æˆ·æ ¹æ®ä»–ä»¬çš„å–œå¥½åšå‡ºæ˜æ™ºçš„å†³å®šã€‚

æˆ‘ä¼šæŒ‰éƒ¨å°±ç­çš„æ€è€ƒï¼Œå…ˆç†è§£å®¢æˆ·çš„éœ€æ±‚ï¼Œç„¶åè€ƒè™‘å„ç§é²œèŠ±çš„æ¶µä¹‰ï¼Œæœ€åæ ¹æ®è¿™ä¸ªéœ€æ±‚ï¼Œç»™å‡ºæˆ‘çš„æ¨èã€‚
åŒæ—¶ï¼Œæˆ‘ä¹Ÿä¼šå‘å®¢æˆ·è§£é‡Šæˆ‘è¿™æ ·æ¨èçš„åŸå› ã€‚

ç¤ºä¾‹ 1:
Â  äººç±»ï¼šæˆ‘æƒ³æ‰¾ä¸€ç§è±¡å¾çˆ±æƒ…çš„èŠ±ã€‚
Â  AIï¼šé¦–å…ˆï¼Œæˆ‘ç†è§£ä½ æ­£åœ¨å¯»æ‰¾ä¸€ç§å¯ä»¥è±¡å¾çˆ±æƒ…çš„èŠ±ã€‚åœ¨è®¸å¤šæ–‡åŒ–ä¸­ï¼Œçº¢ç«ç‘°è¢«è§†ä¸ºçˆ±æƒ…çš„è±¡å¾ï¼Œè¿™æ˜¯å› ä¸ºå®ƒä»¬çš„çº¢è‰²é€šå¸¸ä¸çƒ­æƒ…å’Œæµ“çƒˆçš„æ„Ÿæƒ…è”ç³»åœ¨ä¸€èµ·ã€‚å› æ­¤ï¼Œè€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä¼šæ¨èçº¢ç«ç‘°ã€‚çº¢ç«ç‘°ä¸ä»…èƒ½å¤Ÿè±¡å¾çˆ±æƒ…ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥ä¼ è¾¾å‡ºå¼ºçƒˆçš„æ„Ÿæƒ…ï¼Œè¿™æ˜¯ä½ åœ¨å¯»æ‰¾çš„ã€‚

ç¤ºä¾‹ 2:
Â  äººç±»ï¼šæˆ‘æƒ³è¦ä¸€äº›ç‹¬ç‰¹å’Œå¥‡ç‰¹çš„èŠ±ã€‚
Â  AIï¼šä»ä½ çš„éœ€æ±‚ä¸­ï¼Œæˆ‘ç†è§£ä½ æƒ³è¦çš„æ˜¯ç‹¬ä¸€æ— äºŒå’Œå¼•äººæ³¨ç›®çš„èŠ±æœµã€‚å…°èŠ±æ˜¯ä¸€ç§éå¸¸ç‹¬ç‰¹å¹¶ä¸”é¢œè‰²é²œè‰³çš„èŠ±ï¼Œå®ƒä»¬åœ¨ä¸–ç•Œä¸Šçš„è®¸å¤šåœ°æ–¹éƒ½è¢«è§†ä¸ºå¥¢ä¾ˆå“å’Œç¾çš„è±¡å¾ã€‚å› æ­¤ï¼Œæˆ‘å»ºè®®ä½ è€ƒè™‘å…°èŠ±ã€‚é€‰æ‹©å…°èŠ±å¯ä»¥æ»¡è¶³ä½ å¯¹ç‹¬ç‰¹å’Œå¥‡ç‰¹çš„è¦æ±‚ï¼Œè€Œä¸”ï¼Œå…°èŠ±çš„ç¾ä¸½å’Œå®ƒä»¬æ‰€ä»£è¡¨çš„åŠ›é‡å’Œå¥¢ä¾ˆä¹Ÿå¯èƒ½ä¼šå¸å¼•ä½ ã€‚
"""
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate
system_prompt_role = SystemMessagePromptTemplate.from_template(role_template)
system_prompt_cot = SystemMessagePromptTemplate.from_template(cot_template)

# ç”¨æˆ·çš„è¯¢é—®
human_template = "{human_input}"
human_prompt = HumanMessagePromptTemplate.from_template(human_template)

# å°†ä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ç»“åˆä¸ºä¸€ä¸ªèŠå¤©æç¤º
chat_prompt = ChatPromptTemplate.from_messages([system_prompt_role, system_prompt_cot, human_prompt])

prompt = chat_prompt.format_prompt(human_input="æˆ‘æƒ³ä¸ºæˆ‘çš„å¥³æœ‹å‹è´­ä¹°ä¸€äº›èŠ±ã€‚å¥¹å–œæ¬¢ç²‰è‰²å’Œç´«è‰²ã€‚ä½ æœ‰ä»€ä¹ˆå»ºè®®å—?").to_messages()

# æ¥æ”¶ç”¨æˆ·çš„è¯¢é—®ï¼Œè¿”å›å›ç­”ç»“æœ
response = llm(prompt)
print(response)

```

### Tree of Thought

ToT is a framework for solving complex problems. It guides language models to search a tree of coherent language sequences (intermediate steps to solve the problem) rather than simply generating an answer. The core idea of the ToT framework is to enable the model to generate and evaluate its reasoning capabilities and combine them with search algorithms (such as breadth-first search and depth-first search) for systematic exploration and verification.

![](images/701505/6eec83ffe1a5f37d245520535d65f8a0.png)

The ToT framework defines specific thinking steps and the number of candidates for each step for each task. For example, to solve a mathematical reasoning task, it first breaks it down into three thinking steps, proposes multiple solutions for each step, and retains the top five candidate solutions. Then, it searches for the optimal solution among multiple thinking paths.

The advantage of this method is that the model can better solve problems by observing and evaluating its own thinking process, rather than just generating output based on input. This is very useful for complex tasks that require deep reasoning. Additionally, by introducing techniques such as reinforcement learning and beam search, the performance of search strategies can be further improved, allowing the model to perform better when solving new problems or facing unknown situations.

The ToT framework provides a new approach to solving complex problems by combining the generative capabilities of language models, search algorithms, and reinforcement learning to achieve better results.

## Summary

The concepts of Chain of Thought (CoT) and Tree of Thoughts (ToT) are very interesting and explore how to guide large language models for deeper reasoning.

- The core idea of CoT is to enhance the modelâ€™s reasoning ability by generating a series of intermediate reasoning steps. In the two application methods, Few-Shot CoT and Zero-Shot CoT, the former provides chain-thinking examples to the model, while the latter directly instructs the model to reason step-by-step.
- ToT further expands on the idea of CoT by solving complex problems through searching a tree of coherent language sequences. I demonstrated how to use the ToT framework in practical applications with an example of flower selection.


