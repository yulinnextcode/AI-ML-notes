What is the difference between “agents” and “chains” in LangChain?

My answer is: In chains, a series of operations are hard-coded (in the code). In agents, the language model is used as a reasoning engine to determine which actions to take and in what order to execute them.

The following diagram illustrates the process where an agent receives a task, performs reasoning automatically, and then autonomously calls tools to complete the task.

![](images/708048/aeb7497d833b0b3188fbc7152282b0e3.jpg)

So, you see, the core idea of LangChain and the entire large model application development becomes clear. This core idea is that the sequence of operations is not hard-coded in the code but is chosen by using a language model (such as GPT-3 or GPT-4) to select the sequence of operations.

Here, I repeated the previous statement, which might seem a bit redundant, but this idea is really important. It highlights the value of LLMs as a new programming paradigm where AI autonomously decides the program logic. I hope you understand this carefully.

## Key Components of an Agent
In LangChain, agents have several key components:

- 1. Agent: This class decides what action to take next. It is driven by a language model and a prompt. The prompt may include the agent’s personality (assigning it a role to respond in a specific way), the task’s background (providing more context for the task type), and prompt strategies to elicit better reasoning abilities (such as ReAct). LangChain includes many different types of agents.
- 2. Tools: Tools are functions that the agent calls. There are two important considerations here: ensuring the agent has access to the correct tools and describing these tools in the most helpful way. If you don’t provide the agent with the right tools, it won’t be able to complete the task. If you don’t describe the tools correctly, the agent won’t know how to use them. LangChain provides a range of tools, and you can also define your own.
- 3. Toolkits: A toolkit is a set of related tools used to achieve a specific goal, each containing multiple tools. For example, LangChain’s Office365 toolkit includes tools for connecting to Outlook, reading email lists, sending emails, etc. LangChain also offers many other toolkits for you to use.
- 4. AgentExecutor: The AgentExecutor is the runtime environment for the agent. It calls the agent and executes the actions chosen by the agent. The executor also handles various complex situations, including dealing with the agent selecting non-existent tools, handling tool errors, processing outputs from the agent that cannot be parsed into tool calls, and observing and logging decisions and tool calls.
In summary, an agent is a system that uses a language model to make decisions and call tools to perform specific actions. By setting the agent’s personality, background, and tool descriptions, you can customize the agent’s behavior, enabling it to understand and reason based on the input text, thereby automating task processing. The AgentExecutor is the engine that makes this mechanism work.

In this lecture, we will delve into the internals of LangChain’s source code to reveal how agents make automatic decisions through the AgentExecutor.

## Deep Dive into the AgentExecutor’s Operating Mechanism
Let’s first review the key code from the previous lecture.

```plain
llm = OpenAI(temperature=0) # 大语言模型
tools = load_tools(["serpapi", "llm-math"], llm=llm) # 工具-搜索和数学运算
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True) # 代理
agent.run("目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？") # 运行代理

```

In this code, the initialization of the model, tools, and agent, as well as the agent’s execution process, are extremely concise. However, what is the internal encapsulation logic of LangChain? I hope to help you clarify at least two questions.

1. What does the specific prompt given to the large model by the agent look like each time? What is the secret of this prompt that allows the model to provide the next action guide?
2. How does the AgentExecutor call the model according to the ReAct framework, receive the model’s output, call the tools based on this output, and then generate new prompts based on the tool’s return results?
After running the code, we get the following logs.

![](images/708048/106f1c0f2f34b77473d2b18616a30a73.jpg)

To answer the two questions above, merely observing the LangChain output log is not enough. We need to delve into the internal workings of LangChain’s AgentExecutor.

## Start Debugging
Now, please set a breakpoint at the agent.run statement using your code editor (e.g., VS Code). Use the “Step Into” feature to dive several layers into LangChain’s internal code until we reach the _take_next_step method of the AgentExecutor class in the agent.py file.

This _take_next_step method controls the planning of the next step, where you can see the self.agent.plan method being called, marking the beginning of the planning process.

![](images/708048/99869f62yy0c82a35797d0fc6712736d.jpg)

Note: If you are using VS Code, you need to set the justMyCode option to false in the launch.json file to debug the code within the LangChain package.

![](images/708048/d5accaa1f9a751e7678e7634f2a56942.jpg)

### First Round of Thinking: Model Decides to Search

Driven by the _take_next_step method of the AgentExecutor, we further debug and delve into the self.agent.plan method, arriving at the first step of the entire behavior chain—Plan. The specifics of this Plan are completed by the Plan method of the Agent class. You can see that the input question will be passed to the llm_chain, which then receives the return result from the large model called by llm_chain.

![](images/708048/1d60291f18dc4087b7e166ac5d69d849.jpg)

Taking it a step further, we are about to call the large model. So, what specific prompt information does LangChain pass to the large model to enable it to actively choose tools? The secret lies in the generate method of the LLMChain class, where we can see the specific content of the prompt.

![](images/708048/2e441106b2e8b04eb1806b4f0f46b251.jpg)

During the debugging process, you can observe the prompt, which is the specific content being passed. Here, I’ve copied the prompt for you to take a look at:
```plain
0: StringPromptValue(text='Answer the following questions as best you can. You have access to the following tools:\n\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\nCalculator: Useful for when you need to answer questions about math.\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Search, Calculator]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: 目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\nThought:

```

The prompt I broke down step by step above is the core secret behind why the Agent can drive the large model to engage in the think-act-observe-act-observe cycle. With such a prompt, the model will continuously think and act until it determines that the problem has been solved, providing the final answer and exiting the loop.

```plain
0: LLMResult(generations=[[Generation(text=' I need to find the current market price of roses and then calculate the new price with a 15% markup.\n
Action: Search\nAction Input: "Average price of roses"', generation_info={'finish_reason': 'stop', 'logprobs': None})]],
llm_output={'token_usage': {'completion_tokens': 36, 'total_tokens': 294, 'prompt_tokens': 258}, 'model_name': 'text-davinci-003'}, run=None)

```

It seems that the model realizes it cannot solve the problem with its existing knowledge and needs to choose a tool from the toolbox for the next step. At this point, the command line also outputs the model’s first plan—to call the search tool.

Now that the model knows which tool to call, the first round of the Plan part is over. Next, we move to the tool invocation part of the AgentExecutor’s _take_next_step.

Here, because the model returned an Action as Search, and OutputParse parsed this result, LangChain clearly knows that the Search tool will be called.

After the tool invocation is complete, we have an Observation of the current tool invocation, which is the result of the current tool call.

Next, we need to call the large model again to form a new Thought to see if the task is complete or if we need to call the tool again (either a new tool or the same tool again).


## Second thought: Model determination and calculation

Since the task is not yet complete, the second round of thinking begins, and the program re-enters the Plan phase.

At this point, LangChain’s LLM Chain generates a new prompt based on the current input, which includes the historical conversation records. This updated prompt helps the model decide the next steps in the process.

```plain
0: StringPromptValue(text='Answer the following questions as best you can. You have access to the following tools:\n\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\nCalculator: Useful for when you need to answer questions about math.\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Search, Calculator]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: 目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\nThought: I need to find the current market price of roses and then calculate the new price with a 15% markup.\nAction: Search\nAction Input: "Average price of roses"\nObservation: The average price for a dozen roses in the U.S. is $80.16. The state where a dozen roses cost the most is Hawaii at $108.33. That\'s 35% more expensive than the national average. A dozen roses are most affordable in Pennsylvania, costing $66.15 on average.\nThought:

```

Thought: The following is the content that the large model should further reason about.

Based on the above prompt, the large model returned the following output information:

```plain
AgentAction(tool='Calculator', tool_input='80.16 * 1.15', log=' I need to calculate the new price with a 15% markup.\nAction: Calculator\nAction Input: 80.16 * 1.15')

```

The output shows that the model tells itself, “I need to calculate the new price by adding 15% to the search result,” and determines the action to be using the calculator with the instruction 80.16 * 1.15. This is a very logical thought process.

The parsed Thought output in the command line is as follows:

With the above Thought as guidance, the AgentExecutor calls the second tool: LLMMath. Now, the calculation begins.

Since this math tool also calls the LLM, we can take a look at the internal prompt to see how this tool guides the LLM to perform mathematical calculations.

### Round 3 thought: Model completion

At this point, the Executor’s Plan should further pass the current new result to the large model. As expected, the large model should have enough intelligence to determine that the task has been successfully completed.

下面是目前最新的 prompt。

```plain
0: StringPromptValue(text='Answer the following questions as best you can. You have access to the following tools:\n\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\nCalculator: Useful for when you need to answer questions about math.\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [Search, Calculator]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: 目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\nThought: I need to find the current market price of roses and then calculate the new price with a 15% markup.\nAction: Search\nAction Input: "Average price of roses"\nObservation: The average price for a dozen roses in the U.S. is $80.16. The state where a dozen roses cost the most is Hawaii at $108.33. That\'s 35% more expensive than the national average. A dozen roses are most affordable in Pennsylvania, costing $66.15 on average.\nThought: I need to calculate the new price with a 15% markup.\nAction: Calculator\nAction Input: 80.16 * 1.15\nObservation: Answer: 92.18399999999998\nThought:')

```

Exactly! Each round of prompts follows the model’s chain of thought, gradually progressing and refining. Step by step, the final result becomes clear.

Continuing with the debugging, we see that after this round of thinking, the model’s output finally includes “I now know the final answer,” indicating that the model realizes the task has been successfully completed.

At this point, the AgentExecutor’s plan method returns an AgentFinish instance, indicating that the agent has checked the output and its internal logic has determined that the task is complete, ending the cycle of thinking and acting.

Thus, the entire chain is completed, and the task of the AgentExecutor is finished.

In the command line, the model outputs Thought: I now know the final answer.

The final answer: The average price of the roses is $80.16, and after adding 15%, it is $92.18.

## Summary

In this lesson, we delved into the internal code of the AgentExecutor, exploring its operational mechanism and understanding how it completes the cycle of Thought, Action, and Observation through planning and tool invocation.

When we examine the implementation of the AgentExecutor, we find that this class functions as a chain (Chain) and also executes various tools for the agent to complete tasks. It receives the agent’s plan and executes each step of the agent’s thought process.

The most crucial method in AgentExecutor is the step handling method, _take_next_step. This method is used to take single-step actions in the think-act-observe loop. It first calls the agent’s plan, identifies the tool chosen by the agent, then uses the selected tool to execute the plan (passing the input to the tool at this point), thereby obtaining the observation result. The process continues with further thinking until the output is of the AgentFinish type, at which point the loop ends.





