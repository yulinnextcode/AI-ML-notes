The success of large models largely depends on user input to guide the generation of conversations. If users can describe their tasks and needs in detail and establish a coherent chat context with ChatGPT, ChatGPT often provides more accurate and high-quality answers. However, providing such guidance to the model is a time-consuming and labor-intensive task.

This raises an interesting question: Can ChatGPT generate these guiding texts by itself?

Based on this idea, a research team from KAUST (King Abdullah University of Science and Technology) proposed a framework called CAMEL. CAMEL adopts a large model interaction strategy based on “role-playing.” In this strategy, different AI agents play different roles and complete tasks through mutual communication.

## CAMEL Communicative Agent Framework
Let’s take a look at CAMEL—a framework where multiple AIs interact through role-playing—and its specific implementation in LangChain.

![](images/714249/578c7a5a91ffe7007c0fe4cea3d20bc3.png)

CAMEL, literally meaning camel, comes from the paper “CAMEL: Communicative Agents for ‘Mind’ Exploration of Large Scale Language Model Society.” The name CAMEL actually comes from the first letters of Communicative, Agents, Mind, Exploration, and LLM.

The CAMEL framework aims to promote autonomous cooperation between communicative agents through role-playing and provide insights into their “cognitive” processes. This method involves using inception prompting to guide chat agents to complete tasks while maintaining consistency with human intentions. This framework provides a scalable approach to studying the cooperative behavior and capabilities of multi-agent systems.

There are many new terms in the above introduction, so let’s explain them one by one.

- Communicative Agents are computer programs that can communicate with humans or other agents. These agents can be chatbots, intelligent assistants, or any other software that needs to interact with humans. Researchers have been looking for ways to improve their communication capabilities to make these agents better at interacting with humans.
- Role-playing is the main idea proposed in this paper. It allows communicative agents to play different roles to better interact with humans or other agents. This means that agents can mimic human behavior, understand human intentions, and respond accordingly.
- Inception Prompting is a method of guiding agents to complete tasks. By providing a series of prompts or instructions to the agents, they can better understand how they should act. This method can help agents better communicate with humans and complete cooperative tasks with them.
The core innovation here is to guide the communication process of agents through a framework of role-playing and inception prompting.

## Stock Trading Scenario Design
The paper also proposes the following target scenario and role-playing settings.

![](images/714249/ee865a375320fc2e9e3e690e24766e16.png)

### Scenario and Role Settings
**Human User Role:** Responsible for providing the idea to be realized, such as developing a trading robot for the stock market.

Humans may not know how to realize this idea, but we need to specify roles that might realize this idea, such as a Python programmer and a stock trader.

**Task Specifier Agent**: Responsible for determining a specific task for the AI assistant and AI user based on the input idea. Since the human user’s idea may be vague, the task specifier agent will provide a detailed description to make the idea concrete.

Description: **Develop a trading robot with sentiment analysis capabilities that can monitor positive or negative comments on specific stocks on social media platforms and execute trades based on sentiment analysis results.**

This provides a clear task for the AI assistant to solve.

It is worth mentioning that the task specifier agent is introduced because dialogue agents usually need a specific task prompt to achieve the task. For non-domain experts, creating such a specific task prompt can be challenging or time-consuming.

The AI roles involved in this task include:

- An AI assistant agent with the identity of a Python programmer
- An AI user agent with the identity of a stock trader
After receiving the initial idea and role assignment, the AI user and AI assistant will chat with each other through instruction following. They will cooperate through multiple rounds of dialogue to complete the specified task until the AI user determines that the task is completed.

Among them, the AI user is the task planner, responsible for issuing task-oriented instructions to the AI assistant. On the other hand, the AI assistant is the task executor, designed to follow the AI user’s instructions and provide specific solutions. Here, it will provide the specific Python code for designing the stock trading system.

### Prompt Template Design
In the CAMEL role-playing framework, prompt engineering is crucial. Unlike other dialogue language model technologies, this prompt engineering is only conducted at the initial stage of role-playing, mainly to clarify tasks and assign roles. Once the conversation begins, the AI assistant and AI user will automatically give each other prompts until the conversation ends. This method is called “Inception Prompting.”

Inception Prompting includes three types of prompts: task clarification prompts, AI assistant prompts, and AI user prompts. The paper provides two prompt templates as examples.

In the paper, AI Society and AI Code are two different prompt templates. These prompt templates are designed to guide the interaction between the AI assistant and the AI user.

AI Society: This prompt template mainly focuses on the performance of the AI assistant in various roles. For example, the AI assistant may play multiple roles such as accountant, actor, designer, doctor, engineer, etc., while the user may also have various roles such as blogger, chef, gamer, musician, etc. This setting is to study how the AI assistant cooperates with users of different roles to complete various tasks.

AI Code: This prompt template mainly focuses on programming-related tasks. It involves multiple programming languages such as Java, Python, JavaScript, etc., and multiple fields such as accounting, agriculture, biology, etc. This setting is to study how the AI assistant helps users complete tasks in specific programming languages and fields.

![](images/714249/8258bbe76e664b41ce636bfa8655c4f4.png)

![](images/714249/d824e74e324556232d86f20a3ab6e6e2.png)

Taking AI Society as an example, this prompt template is designed for the AI assistant system and AI user system. It provides initial prompts at the beginning of role-playing. Here is a detailed explanation of this template.

![](images/714249/cc725b0b74f2a066acdefc7c9a3c7da5.jpg)

This prompt template provides a clear framework for the AI assistant and AI user, ensuring that their behavior in the conversation is orderly, consistent, and effective. It can be seen that, unlike the traditional prompt design, this prompt design is more complex and detailed, more like an interaction protocol or specification. This design improves the autonomous cooperation ability between AI and AI to a certain extent and can better simulate the interaction process between humans.

## Yisu Flower Marketing Plan
Okay, after reading the ideas of the paper and the examples given in the paper, we will start our own CAMEL practice with “Yisu Flowers” as the background.

### Preparation
First, import the API key and the required libraries.
```plain
# 设置OpenAI API密钥
import os
os.environ["OPENAI_API_KEY"] = 'Your Key'

# 导入所需的库
from typing import List
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import (
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain.schema import (
    AIMessage,
    HumanMessage,
    SystemMessage,
    BaseMessage,
)

```
### Define the CAMELAgent class

Below is the definition of the CAMELAgent class. This is a core class used to manage interactions with the language model. It includes methods for initializing messages, updating messages, and interacting with the model.

```plain
# 定义CAMELAgent类，用于管理与语言模型的交互
class CAMELAgent:
    def __init__(
        self,
        system_message: SystemMessage,
        model: ChatOpenAI,
    ) -> None:
        self.system_message = system_message
        self.model = model
        self.init_messages()

    def reset(self) -> None:
        """重置对话消息"""
        self.init_messages()
        return self.stored_messages

    def init_messages(self) -> None:
        """初始化对话消息"""
        self.stored_messages = [self.system_message]

    def update_messages(self, message: BaseMessage) -> List[BaseMessage]:
        """更新对话消息列表"""
        self.stored_messages.append(message)
        return self.stored_messages

    def step(self, input_message: HumanMessage) -> AIMessage:
        """进行一步交互，并获取模型的响应"""
        messages = self.update_messages(input_message)

        output_message = self.model(messages)
        self.update_messages(output_message)

        return output_message

```

### Preset Roles and Task Prompts

The preset roles and task prompts define the role names for the AI assistant and user, the task description, and the word limit for each discussion.

```plain
# 设置一些预设的角色和任务提示
assistant_role_name = "花店营销专员"
user_role_name = "花店老板"
task = "整理出一个夏季玫瑰之夜的营销活动的策略"
word_limit = 50  # 每次讨论的字数限制

```
Here, assistant_role_name and user_role_name are used to define the roles of the agents. These roles play different functions in the subsequent conversations, specifically set as follows:

- assistant_role_name = "Flower Shop Marketing Specialist": This defines the role of the assistant. In this setting, the assistant is viewed as a flower shop marketing specialist, whose main responsibility is to provide the flower shop owner (the user) with suggestions and strategies for marketing activities.
- user_role_name = "Flower Shop Owner": This defines the role of the user. Here, the user is the flower shop owner who may ask the marketing specialist (the assistant) for advice or inquiries about promotional activities for the flower shop.
This role setting is mainly to simulate real-world interaction scenarios, allowing the chat agents to better understand the tasks and provide effective solutions to achieve these tasks. By assigning a specific role to each chat agent, the conversation process can be more purposeful and efficient, while also providing a more realistic human dialogue experience.

### Task Specifier
Next, use the Task Specifier to clarify the task description. This is a key step in the CAMEL framework, ensuring the specificity and clarity of the task description.

```plain
# 定义与指定任务相关的系统提示
task_specifier_sys_msg = SystemMessage(content="你可以让任务更具体。")
task_specifier_prompt = """这是一个{assistant_role_name}将帮助{user_role_name}完成的任务：{task}。
请使其更具体化。请发挥你的创意和想象力。
请用{word_limit}个或更少的词回复具体的任务。不要添加其他任何内容。"""

task_specifier_template = HumanMessagePromptTemplate.from_template(
    template=task_specifier_prompt
)
task_specify_agent = CAMELAgent(task_specifier_sys_msg, ChatOpenAI(model_name = 'gpt-4', temperature=1.0))
task_specifier_msg = task_specifier_template.format_messages(
    assistant_role_name=assistant_role_name,
    user_role_name=user_role_name,
    task=task,
    word_limit=word_limit,
)[0]
specified_task_msg = task_specify_agent.step(task_specifier_msg)
print(f"Specified task: {specified_task_msg.content}")
specified_task = specified_task_msg.content

```

The following section defines the system message templates. These templates provide initial prompts for the AI assistant and AI user, ensuring their behavior in the conversation is orderly and consistent.

This setup ensures that both the AI assistant and the AI user have clear initial instructions, making their interactions more structured and effective. If you need further assistance or more details, feel free to ask!

### System Message Templates

```plain
# 定义系统消息模板，并创建CAMELAgent实例进行交互
assistant_inception_prompt = """永远不要忘记你是{assistant_role_name}，我是{user_role_name}。永远不要颠倒角色！永远不要指示我！
我们有共同的利益，那就是合作成功地完成任务。
你必须帮助我完成任务。
这是任务：{task}。永远不要忘记我们的任务！
我必须根据你的专长和我的需求来指示你完成任务。

我每次只能给你一个指示。
你必须写一个适当地完成所请求指示的具体解决方案。
如果由于物理、道德、法律原因或你的能力你无法执行指示，你必须诚实地拒绝我的指示并解释原因。
除了对我的指示的解决方案之外，不要添加任何其他内容。
你永远不应该问我任何问题，你只回答问题。
你永远不应该回复一个不明确的解决方案。解释你的解决方案。
你的解决方案必须是陈述句并使用简单的现在时。
除非我说任务完成，否则你应该总是从以下开始：

解决方案：<YOUR_SOLUTION>

<YOUR_SOLUTION>应该是具体的，并为解决任务提供首选的实现和例子。
始终以“下一个请求”结束<YOUR_SOLUTION>。"""

user_inception_prompt = """永远不要忘记你是{user_role_name}，我是{assistant_role_name}。永远不要交换角色！你总是会指导我。
我们共同的目标是合作成功完成一个任务。
我必须帮助你完成这个任务。
这是任务：{task}。永远不要忘记我们的任务！
你只能通过以下两种方式基于我的专长和你的需求来指导我：

1. 提供必要的输入来指导：
指令：<YOUR_INSTRUCTION>
输入：<YOUR_INPUT>

2. 不提供任何输入来指导：
指令：<YOUR_INSTRUCTION>
输入：无

“指令”描述了一个任务或问题。与其配对的“输入”为请求的“指令”提供了进一步的背景或信息。

你必须一次给我一个指令。
我必须写一个适当地完成请求指令的回复。
如果由于物理、道德、法律原因或我的能力而无法执行你的指令，我必须诚实地拒绝你的指令并解释原因。
你应该指导我，而不是问我问题。
现在你必须开始按照上述两种方式指导我。
除了你的指令和可选的相应输入之外，不要添加任何其他内容！
继续给我指令和必要的输入，直到你认为任务已经完成。
当任务完成时，你只需回复一个单词<CAMEL_TASK_DONE>。
除非我的回答已经解决了你的任务，否则永远不要说<CAMEL_TASK_DONE>。"""

```

之后，根据预设的角色和任务提示生成系统消息。

```plain
# 根据预设的角色和任务提示生成系统消息
def get_sys_msgs(assistant_role_name: str, user_role_name: str, task: str):
    assistant_sys_template = SystemMessagePromptTemplate.from_template(
        template=assistant_inception_prompt
    )
    assistant_sys_msg = assistant_sys_template.format_messages(
        assistant_role_name=assistant_role_name,
        user_role_name=user_role_name,
        task=task,
    )[0]

    user_sys_template = SystemMessagePromptTemplate.from_template(
        template=user_inception_prompt
    )
    user_sys_msg = user_sys_template.format_messages(
        assistant_role_name=assistant_role_name,
        user_role_name=user_role_name,
        task=task,
    )[0]

    return assistant_sys_msg, user_sys_msg

assistant_sys_msg, user_sys_msg = get_sys_msgs(
    assistant_role_name, user_role_name, specified_task
)

```

### Create Agent instance

创建助手和用户的CAMELAgent实例，并初始化对话互动，使用CAMELAgent类的实例来模拟助手和用户之间的对话交互。

```plain
# 创建助手和用户的CAMELAgent实例
assistant_agent = CAMELAgent(assistant_sys_msg, ChatOpenAI(temperature=0.2))
user_agent = CAMELAgent(user_sys_msg, ChatOpenAI(temperature=0.2))

# 重置两个agent
assistant_agent.reset()
user_agent.reset()

# 初始化对话互动
assistant_msg = HumanMessage(
    content=(
        f"{user_sys_msg.content}。"
        "现在开始逐一给我介绍。"
        "只回复指令和输入。"
    )
)

user_msg = HumanMessage(content=f"{assistant_sys_msg.content}")
user_msg = assistant_agent.step(user_msg)

print(f"Original task prompt:\n{task}\n")
print(f"Specified task prompt:\n{specified_task}\n")

```

这里，assistant\_inception\_prompt 和 user\_inception\_prompt 是两个关键的提示，用于引导聊天代理的行为和交流方式。关于这两个提示，让我们一起来深入理解一下它们的设计和目标。

1. **assistant\_inception\_prompt：** 这个提示是为了引导助手（即营销专员）如何响应用户（即花店老板）的指示。它明确指出助手的角色和职责，强调了在完成任务的过程中需要遵循的一些基本规则和原则。例如，助手需要针对用户的每一个指示提供一个明确的解决方案，而且这个解决方案必须是具体、易于理解的，并且只有在遇到物理、道德、法律的限制或自身能力的限制时，才能拒绝用户的指示。这个提示的设计目标是引导助手在一次有目标的对话中，有效地对用户的指示做出响应。
2. **user\_inception\_prompt：** 这个提示是为了引导用户（即花店老板）如何给助手（即营销专员）下达指示。它明确指出了用户的角色和职责，强调了在提出任务指示时需要遵循的一些基本规则和原则。例如，用户需要一次只给出一个指示，并且必须清楚地提供相关的输入（如果有的话）。而且用户在给出指示的同时，不能向助手提问。这个提示的设计目标是引导用户在一次有目标的对话中，有效地给出指示，以便助手能够更好地理解和完成任务。

这两个提示的设计都体现了一种“角色扮演”的机制，即通过赋予聊天代理具体的角色和职责，以帮助它们更好地理解和完成任务。这种机制可以有效地引导聊天代理的交流行为，使得对话更加有目的性和效率，同时也能提供更为真实的人类对话体验。

### Brain storming begin

接下来，模拟助手和用户之间的多轮对话，直到达到对话轮次上限或任务完成。

```plain
# 模拟对话交互，直到达到对话轮次上限或任务完成
chat_turn_limit, n = 30, 0
while n < chat_turn_limit:
    n += 1
    user_ai_msg = user_agent.step(assistant_msg)
    user_msg = HumanMessage(content=user_ai_msg.content)
    print(f"AI User ({user_role_name}):\n\n{user_msg.content}\n\n")

    assistant_ai_msg = assistant_agent.step(user_msg)
    assistant_msg = HumanMessage(content=assistant_ai_msg.content)
    print(f"AI Assistant ({assistant_role_name}):\n\n{assistant_msg.content}\n\n")
    if "<CAMEL_TASK_DONE>" in user_msg.content:
        break

```

运行程序，营销策划头脑风暴开始！

![](images/714249/453054aabe9d816ff88e05bb6ca03390.jpg)

![](images/714249/dff9cdf1f992756a3a02e48f63e96d01.jpg)

![](images/714249/219851d4806bd8fa01f7ee09ac0f715c.jpg)

![](images/714249/dc6fb40781a2e53017e7d48d18f96a6f.jpg)

![](images/714249/7c01866d547f9517787cf25cd4a65587.jpg)

怎么样，看到这样的策划水准，是否觉得CAMEL框架趋动的AI助理完全不输给一个专业的营销策划专员呢？

讲到这里，我冒出了两个想法。是不是只有我们想不到，没有AI做不到的？一大批人可能真的要失业了。所以，赶快学习吧！继续卷起来。

## Summary

Intelligent agents will play increasingly important roles in the future. To better serve humans, we need to find ways to improve their communication capabilities. The CAMEL paper offers a new perspective on the development of communicative agents. By using a “role-playing” framework, more intelligent and human-like communicative agents can be developed, bringing more convenience to our daily lives.

Let’s also review the implementation of the CAMEL framework and the special aspects of prompt design in this implementation:

- 1. Role-playing: Each agent is assigned a role with clear responsibilities and behavior guidelines. For example, the Python programmer (assistant) provides specific solutions based on the stock trader’s (user) instructions, while the stock trader provides detailed task instructions. This role-playing mechanism helps simulate human interactions more realistically to complete tasks.
- 2. Task Specification: To help AI better understand and execute tasks, the step of specifying abstract tasks is proposed. This helps AI understand task requirements more clearly and provide more accurate solutions.
- 3. Initial Prompts: To start the conversation and provide appropriate guidance, the system initializes with two initial prompts—one for the assistant role and one for the user role. These prompts describe the behavior guidelines and task details for each role, providing a framework and guidance for the entire conversation.
- 4. Interaction Norms: The code implementation includes clear interaction norms, such as giving one instruction at a time, requiring detailed explanations for solutions, and starting outputs with “Solution:”. These norms help maintain clarity and efficiency in the conversation.

Unlike traditional prompt design, the prompts in CAMEL are more complex and detailed, resembling an interaction protocol or specification. This design improves the autonomous cooperation ability between AI agents and better simulates human interactions.





